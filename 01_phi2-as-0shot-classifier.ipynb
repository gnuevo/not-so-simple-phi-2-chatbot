{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "760f5767-6e2d-4f63-87c3-b199c973a5cd",
   "metadata": {},
   "source": [
    "# Phi2 - 0-shot classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0252d32-9b33-44c0-8e2c-f747a1934600",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/grego/code/jobsearch/ipglobal-2/env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM, \n",
    "    AutoTokenizer, \n",
    "    StoppingCriteria, \n",
    "    StoppingCriteriaList, \n",
    "    TextIteratorStreamer\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e4590a1-dbb6-4ada-87f7-487bc2f47bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from samples import samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b62eedbf-2cf4-4d62-a7c4-974ccc779439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your device is cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  2.76it/s]\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Your device is\", device)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"microsoft/phi-2\", \n",
    "    device_map=\"auto\", \n",
    "    torch_dtype=\"auto\" if device == \"cuda\" else torch.float, \n",
    "    trust_remote_code=True\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"microsoft/phi-2\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9568dd84-48fb-482e-a64d-5ce20c15aa9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StopOnTokens(StoppingCriteria):\n",
    "    \"\"\"Stops the model if it produces an 'end of text' token\"\"\"\n",
    "    def __call__(self, input_ids: torch.LongTensor, \n",
    "                 scores: torch.FloatTensor, **kwargs) -> bool:\n",
    "        stop_ids = [50256, 198] # <|endoftext|> and EOL\n",
    "        for stop_id in stop_ids:\n",
    "            if input_ids[0][-1] == stop_id:\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "stop = StopOnTokens()\n",
    "\n",
    "def run_prompt(prompt):\n",
    "    with torch.no_grad():\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\", return_attention_mask=False).to(device)\n",
    "        outputs = model.generate(**inputs, max_length=250, stopping_criteria=[stop])\n",
    "        text = tokenizer.batch_decode(outputs)[0]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ed0026f-9e65-4a45-9779-4e398d022662",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "Instruct: Classify the following text in one of the following categories: [\"support\", \"sales\", \"joke\"]\n",
    "Text: {samples['support'][0]}\n",
    "Output:\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf7d4f12-cded-4a45-b20b-afb92173743e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instruct: Classify the following text in one of the following categories: [\"support\", \"sales\", \"joke\"]\n",
      "Text: Hi, I have an issue with my order. It hasn't arrived, and the delivery date has passed.\n",
      "Output: sales\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(run_prompt(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44a5bad9-4c11-4c47-ab90-819d30beddcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "Instruct: Classify the following text in one of the following categories: [\"support\", \"sales\", \"joke\"]. Output only the name of the category.\n",
    "+ \"support\" for customer support texts\n",
    "+ \"sales\" for sales and commercial texts\n",
    "+ \"joke\" for jokes, funny or comedy like texts\n",
    "Text: {}\n",
    "Output:\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "756cb075-16d7-4325-82ad-9119c0d2f51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_labels = [\"customer support\", \"sales and comercial\", \"joke\"]\n",
    "labels_short = [\"support\", \"sales\", \"joke\"]\n",
    "\n",
    "def long_to_short(label):\n",
    "    return labels_short[candidate_labels.index(label)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e712a28-efc8-490e-bb1d-f6be3fc95d3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'support': 21, 'sales': 4, 'joke': 0}\n",
      "{'support': 3, 'sales': 22, 'joke': 0}\n",
      "{'support': 0, 'sales': 0, 'joke': 25}\n"
     ]
    }
   ],
   "source": [
    "for k in samples.keys():\n",
    "    d = {k: 0 for k in labels_short}\n",
    "    for s in samples[k]:\n",
    "        text = template.format(s)\n",
    "        label = run_prompt(text).split()[-1]\n",
    "        d[label.lower()] += 1\n",
    "    print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6ec0b8-a3c1-4452-8d6f-1e91c9602f9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 Ipglobal 2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
